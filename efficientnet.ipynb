{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parameter\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.models.efficientnet\n",
    "from torchvision.models.feature_extraction import (\n",
    "    get_graph_node_names,\n",
    "    create_feature_extractor,\n",
    ")\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import efficientnet\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $EfficientNetV_2-small$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (\n",
    "    models.EfficientNet_V2_S_Weights.DEFAULT\n",
    ")  # models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "\n",
    "effnetv2s = models.efficientnet_v2_s(weights=weights)\n",
    "\n",
    "train_nodes = get_graph_node_names(effnetv2s)\n",
    "train_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetv2s.classifier[1] = nn.Linear(in_features=1280, out_features=10572)\n",
    "effnetv2s.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 112, 112)\n",
    "\n",
    "return_nodes = {\n",
    "    \"features.0\": \"feature0\",\n",
    "    \"features.1\": \"feature1\",\n",
    "    \"features.2\": \"feature2\",\n",
    "    \"features.3\": \"feature3\",\n",
    "    \"features.4\": \"feature4\",\n",
    "    \"features.5\": \"feature5\",\n",
    "    \"features.6\": \"feature6\",\n",
    "    \"features.7\": \"feature7\",\n",
    "    \"avgpool\": \"avgpool2d\",\n",
    "    \"flatten\": \"flat_vec\",\n",
    "    \"classifier.0\": \"class0\",\n",
    "    \"classifier.1\": \"class1\",\n",
    "}\n",
    "\n",
    "features = create_feature_extractor(effnetv2s, return_nodes=return_nodes)\n",
    "layer_feature = features(x)\n",
    "\n",
    "print(\"feature.0 = \", layer_feature[\"feature0\"].shape)\n",
    "print(\"feature.1 = \", layer_feature[\"feature1\"].shape)\n",
    "print(\"feature.2 = \", layer_feature[\"feature2\"].shape)\n",
    "print(\"feature.3 = \", layer_feature[\"feature3\"].shape)\n",
    "print(\"feature.4 = \", layer_feature[\"feature4\"].shape)\n",
    "print(\"feature.5 = \", layer_feature[\"feature5\"].shape)\n",
    "print(\"feature.6 = \", layer_feature[\"feature6\"].shape)\n",
    "print(\"feature.7 = \", layer_feature[\"feature7\"].shape)\n",
    "print(\"avgpool = \", layer_feature[\"avgpool2d\"].shape)\n",
    "print(\"flatten = \", layer_feature[\"flat_vec\"].shape)\n",
    "print(\"classifier.0 = \", layer_feature[\"class0\"].shape)\n",
    "print(\"classifier.0 = \", layer_feature[\"class1\"].shape)\n",
    "\n",
    "print(layer_feature[\"feature7\"].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EfficientNetV2S model\n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "\n",
    "# Print the names and types of all the layers in the model\n",
    "for name, layer in model.named_children():\n",
    "    print(name, type(layer))\n",
    "\n",
    "# Or, if you only want to print the layer names\n",
    "for name, _ in model.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained=True, fine_tune=True, num_classes=10572):\n",
    "    if pretrained:\n",
    "        print(\"[INFO]: Loading pre-trained weights\")\n",
    "    else:\n",
    "        print(\"[INFO]: Not loading pre-trained weights\")\n",
    "\n",
    "    weights = (\n",
    "        torchvision.models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "    )  # or torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = torchvision.models.efficientnet_v2_s(weights=weights)\n",
    "\n",
    "    if fine_tune:\n",
    "        print(\"[INFO]: Fine-tuning all layers...\")\n",
    "        for params in model.parameters():\n",
    "            params.requires_grad = True\n",
    "    elif not fine_tune:\n",
    "        print(\"[INFO]: Freezing hidden layers...\")\n",
    "        for params in model.parameters():\n",
    "            params.requires_grad = False\n",
    "    # Change the final classification head.\n",
    "    model.classifier[1] = nn.Linear(\n",
    "        in_features=1280,\n",
    "        out_features=num_classes,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_ViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = (\n",
    "            models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "        )  # models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "        self.pt_model = models.efficientnet_v2_s(weights=weights)\n",
    "        self.trimmed_model = nn.Sequential(*list(self.pt_model.children())[:-2])\n",
    "        self.pt_model = None\n",
    "        for child in self.trimmed_model.children():\n",
    "            for name, param in child.named_parameters():\n",
    "                print(\"==\" * 60)\n",
    "                print(\"Child name\", name, \"Parameter Gradient\", param.requires_grad)\n",
    "\n",
    "        print(\"++\" * 20)\n",
    "        print(self.pt_model)\n",
    "        print(\"++\" * 20)\n",
    "        print(self.trimmed_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trimmed_model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 224, 224)\n",
    "effnet_vit = EfficientNet_ViT()\n",
    "op = effnet_vit(x)\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 112, 112)\n",
    "effnet_vit = EfficientNet_ViT()\n",
    "op = effnet_vit(x)\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op.shape)\n",
    "print(\"=\" * 60)\n",
    "# print(effnet_vit)\n",
    "for n, c in effnetv2s.named_children():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $EfficientNetV_1-b_0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "effnetb0 = torchvision.models.efficientnet_b0(weights=weights)\n",
    "train_nodes = get_graph_node_names(effnetb0)\n",
    "train_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 112, 112)\n",
    "\n",
    "return_nodes = {\n",
    "    \"features.0\": \"feature0\",\n",
    "    \"features.1\": \"feature1\",\n",
    "    \"features.2\": \"feature2\",\n",
    "    \"features.3\": \"feature3\",\n",
    "    \"features.4\": \"feature4\",\n",
    "    \"features.5\": \"feature5\",\n",
    "    \"features.6\": \"feature6\",\n",
    "    \"features.7\": \"feature7\",\n",
    "    \"features.8\": \"feature8\",\n",
    "    \"avgpool\": \"avgpool2d\",\n",
    "    \"flatten\": \"flat_vec\",\n",
    "    \"classifier.0\": \"class0\",\n",
    "    \"classifier.1\": \"class1\",\n",
    "}\n",
    "\n",
    "features = create_feature_extractor(effnetb0, return_nodes=return_nodes)\n",
    "layer_feature = features(x)\n",
    "\n",
    "print(\"feature.0 = \", layer_feature[\"feature0\"].shape)\n",
    "print(\"feature.1 = \", layer_feature[\"feature1\"].shape)\n",
    "print(\"feature.2 = \", layer_feature[\"feature2\"].shape)\n",
    "print(\"feature.3 = \", layer_feature[\"feature3\"].shape)\n",
    "print(\"feature.4 = \", layer_feature[\"feature4\"].shape)\n",
    "print(\"feature.5 = \", layer_feature[\"feature5\"].shape)\n",
    "print(\"feature.6 = \", layer_feature[\"feature6\"].shape)\n",
    "print(\"feature.7 = \", layer_feature[\"feature7\"].shape)\n",
    "print(\"feature.8 = \", layer_feature[\"feature8\"].shape)\n",
    "print(\"avgpool = \", layer_feature[\"avgpool2d\"].shape)\n",
    "print(\"flatten = \", layer_feature[\"flat_vec\"].shape)\n",
    "print(\"classifier.0 = \", layer_feature[\"class0\"].shape)\n",
    "print(\"classifier.0 = \", layer_feature[\"class1\"].shape)\n",
    "\n",
    "print(layer_feature[\"feature8\"].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model._blocks))\n",
    "print(model._blocks[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(1, 3, 112, 112)\n",
    "endpoints = model.extract_endpoints(inputs)\n",
    "print(endpoints[\"reduction_2\"].size())\n",
    "print(endpoints[\"reduction_3\"].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Trimmed\\  EfficientNet + ViT$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_args, global_params = efficientnet(\n",
    "    width_coefficient=1.0,\n",
    "    depth_coefficient=1.0,\n",
    "    image_size=112,\n",
    "    dropout_rate=0.2,\n",
    "    drop_connect_rate=0.2,\n",
    "    num_classes=10572,\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "blocks_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocks_args)\n",
    "print(global_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet(\n",
    "    blocks_args=blocks_args,\n",
    "    global_params=global_params,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model._blocks))\n",
    "print(list(model._modules.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, c in model.named_children():\n",
    "    print(n)\n",
    "    if n == \"_blocks\":\n",
    "        print(c._modules.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model._blocks[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetTrim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.pt_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        # 210224 1324 create model from scratch without using pretrained weights\n",
    "        blocks_args, global_params = efficientnet(\n",
    "            width_coefficient=1.0,\n",
    "            depth_coefficient=1.0,\n",
    "            image_size=112,\n",
    "            dropout_rate=0.2,\n",
    "            drop_connect_rate=0.2,\n",
    "            num_classes=10572,\n",
    "            include_top=False,\n",
    "        )\n",
    "        self.pt_model = EfficientNet(\n",
    "            blocks_args=blocks_args, global_params=global_params\n",
    "        )\n",
    "        self.layers = list(\n",
    "            self.pt_model._modules.keys()\n",
    "        )  # ['_conv_stem', '_bn0', '_blocks', '_conv_head', '_bn1', '_avg_pooling', '_dropout', '_fc', '_swish'] # Convertion from Odict_keys\n",
    "        self.layer_count = 0\n",
    "        for l in self.layers:\n",
    "            if l != \"_blocks\":\n",
    "                self.layer_count += 1\n",
    "            else:\n",
    "                self.pt_model._blocks = nn.Sequential(\n",
    "                    *[self.pt_model._blocks[i] for i in range(4)]\n",
    "                )  # Added to solve ModuleList problem\n",
    "                break\n",
    "        print(\"Layer Count\", self.layer_count)\n",
    "        print(\"Length of _blocks\", len(self.pt_model._blocks))\n",
    "        for i in range(1, len(self.layers) - self.layer_count):\n",
    "            l = self.layers[-i]\n",
    "            self.dummy_var = self.pt_model._modules.pop(self.layers[-i])\n",
    "            print(\"popped Layer\", l, self.dummy_var)\n",
    "        # self.pt_model_trim = nn.Sequential(*list(self.pt_model._modules))\n",
    "        self.pt_model_trim = nn.Sequential(self.pt_model._modules)\n",
    "        self.pt_model = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for n, c in self.pt_model_trim.named_children():\n",
    "            print(n)  # returns _conv_stem   _bn0   _blocks\n",
    "            print(type(c))\n",
    "            for m, p in c.named_parameters():\n",
    "                print(m, p.requires_grad)  # returns True\n",
    "        return self.pt_model_trim(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = EfficientNetTrim()\n",
    "# summary(new_model,input_size=(3, 224, 224))\n",
    "\n",
    "x = torch.rand(1, 3, 112, 112)\n",
    "efficientnet_trim = EfficientNetTrim()\n",
    "output = efficientnet_trim(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\n",
    "    \"./results/EfficientNet_Trim_ViT_casia_cosface_s1/Backbone_EffNet_trim_VIT_checkpoint.pth\"\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./results/EfficientNet_Trim_ViT_casia_cosface_s1/Backbone_EffNet_trim_VIT_checkpoint.pth\"\n",
    "model = torch.load(\n",
    "    \"./results/EfficientNet_Trim_ViT_casia_cosface_s1/Backbone_EffNet_trim_VIT_checkpoint.pth\"\n",
    ")\n",
    "# state = {\n",
    "#     \"model_state_dict\": model.state_dict(),\n",
    "# }\n",
    "# torch.save(state, PATH)\n",
    "model.load_state_dict(torch.load(PATH)[\"model\"])\n",
    "# print weights\n",
    "for key, val in model.named_parameters():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Classes: 10572\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"./Data/casia-webface/\"\n",
    "INPUT_SIZE = [112, 112]\n",
    "with open(os.path.join(DATA_ROOT, \"property\"), \"r\") as f:\n",
    "    NUM_CLASS, h, w = [int(i) for i in f.read().split(\",\")]\n",
    "assert h == INPUT_SIZE[0] and w == INPUT_SIZE[1]\n",
    "print(\"Number of Training Classes: {}\".format(NUM_CLASS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
